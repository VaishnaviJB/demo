{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37597f7",
   "metadata": {},
   "source": [
    "# Build a NLP Language model for text generation involves train a neural network to predict the next word in a sequence of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a31ff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Users\\vaish\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Users\\vaish\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Users\\vaish\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From F:\\Users\\vaish\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Users\\vaish\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.9415 - accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9296 - accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9177 - accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9056 - accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8933 - accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.8804 - accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8670 - accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.8527 - accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8375 - accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8213 - accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8037 - accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7847 - accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7641 - accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7418 - accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7174 - accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6909 - accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6620 - accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6307 - accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5968 - accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5603 - accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5212 - accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4797 - accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4361 - accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3906 - accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3436 - accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2955 - accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2464 - accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1964 - accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1452 - accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0924 - accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0382 - accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9825 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9260 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8697 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8144 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7606 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7081 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6565 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6056 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5557 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5077 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4625 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3801 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3089 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2786 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2519 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2283 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2076 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1897 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1739 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1601 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1475 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1251 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1149 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1052 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0961 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0797 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0725 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "i will become ai solution developer. become senior sofware engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer engineer\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Sample text data\n",
    "text = \"vaish will become senior sofware engineer.\"\n",
    "\n",
    "# Preprocess the text\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences and labels\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "x, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, epochs=100, verbose=1)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(seed_text, next_words, model, max_sequence_length):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(\"i will become ai solution developer.\", 20, model, max_sequence_length)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b14378",
   "metadata": {},
   "source": [
    "# Build a Speech to Text model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2a2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in f:\\users\\vaish\\anaconda3\\lib\\site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Using cached pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975cb942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition==3.8.1Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition==3.8.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fd8b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Uberi/speech_recognition\n",
      "  Cloning https://github.com/Uberi/speech_recognition to c:\\users\\vaish\\appdata\\local\\temp\\pip-req-build-qw6ytems\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git version\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/Uberi/speech_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4372db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading PyAudio-0.2.14-cp311-cp311-win_amd64.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/164.1 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 92.2/164.1 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 164.1/164.1 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df96322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d19cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something:\n",
      "You said: say something hi hello how are you\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def speech_to_text():\n",
    "    # Initialize the recognizer\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Capture audio from the microphone\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something:\")\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        # Use Google Speech Recognition to convert audio to text\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"You said: {}\".format(text))\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Error with the speech recognition service: {}\".format(e))\n",
    "\n",
    "# Call the function\n",
    "speech_to_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb2caef",
   "metadata": {},
   "source": [
    "# Build a Text to Speech model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09676f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Using cached gTTS-2.4.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in f:\\users\\vaish\\anaconda3\\lib\\site-packages (from gtts) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in f:\\users\\vaish\\anaconda3\\lib\\site-packages (from gtts) (8.0.4)\n",
      "Requirement already satisfied: colorama in f:\\users\\vaish\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\users\\vaish\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\users\\vaish\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\users\\vaish\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\users\\vaish\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n",
      "Using cached gTTS-2.4.0-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gtts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d0bc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "def text_to_speech(text, language='en', filename='output.mp3'):\n",
    "    # Create a gTTS object\n",
    "    tts = gTTS(text=text, lang=language, slow=False)\n",
    "\n",
    "    # Save the audio file\n",
    "    tts.save(filename)\n",
    "\n",
    "    # Play the generated audio file\n",
    "    os.system(f'start {filename}')\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, this is a Text-to-Speech model built with gTTS.\"\n",
    "text_to_speech(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b6cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dba0c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a09b7c38",
   "metadata": {},
   "source": [
    "# Build a NLP Language model to detect the sentence/word error in the text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "921ecc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb55374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Download the English language model\n",
    "spacy.cli.download(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73809089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Sentence errors:\n",
      "- \n",
      "    \n",
      "- It is importnt to check for erorrs in sentences and words. \n",
      "    \n",
      "- This is a simple example.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Download the English language model\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "def detect_errors(text):\n",
    "    # Load the pre-trained English language model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Check for sentence errors\n",
    "    sentence_errors = []\n",
    "    for sent in doc.sents:\n",
    "        if sent.text.strip() != sent.text:\n",
    "            sentence_errors.append(sent.text)\n",
    "\n",
    "    # Check for word errors\n",
    "    word_errors = []\n",
    "    for token in doc:\n",
    "        if token.is_alpha and not token.is_stop and not token.is_punct and not token.is_space:\n",
    "            # Perform your own word error detection logic here\n",
    "            # For simplicity, we'll consider words with length less than 3 as errors\n",
    "            if len(token.text) < 3:\n",
    "                word_errors.append(token.text)\n",
    "\n",
    "    return sentence_errors, word_errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_corpus = \"\"\"\n",
    "    This is a sample text with some errors. It is importnt to check for erorrs in sentences and words. \n",
    "    Also, words with len less than 3 might be considered as errors. This is a simple example.\n",
    "    \"\"\"\n",
    "\n",
    "    sentence_errors, word_errors = detect_errors(text_corpus)\n",
    "\n",
    "    if sentence_errors:\n",
    "        print(\"Sentence errors:\")\n",
    "        for error in sentence_errors:\n",
    "            print(f\"- {error}\")\n",
    "\n",
    "    if word_errors:\n",
    "        print(\"\\nWord errors:\")\n",
    "        for error in word_errors:\n",
    "            print(f\"- {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc13afca",
   "metadata": {},
   "source": [
    "# Build a Language model to correct the error in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2edbc4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a26d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\vaish\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text with errors:\n",
      "This is a sample text with some erorrs. It is importnt to check for erorrs in sentences and words.\n",
      "\n",
      "Corrected text:\n",
      "This is a sample text with some erorrs. It is importnt to check for erorrs in sentences and words.\n",
      "\n",
      "import numpy as np import random as pd import sys import time import csv import json import pandas as plt import matplotlib.pyplot as tpl import reStructuredText as r = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def correct_errors(text):\n",
    "    # Load pre-trained GPT-2 model and tokenizer\n",
    "    model_name = \"gpt2\"\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize and generate corrections\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "\n",
    "    corrected_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_with_errors = \"This is a sample text with some erorrs. It is importnt to check for erorrs in sentences and words.\"\n",
    "\n",
    "    corrected_text = correct_errors(text_with_errors)\n",
    "\n",
    "    print(\"Original text with errors:\")\n",
    "    print(text_with_errors)\n",
    "\n",
    "    print(\"\\nCorrected text:\")\n",
    "    print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ab86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
